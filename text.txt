# EXP 2: write a program to implement a fully connected deep neural network with atleast 2 hidden layers for a classification application.

In this program, the classification task is on the Iris dataset.
Specifically:
Input features (X): 4 numeric features per flower sample
- sepal length
- sepal width
- petal length
- petal width
Target (y): the species of iris flower
0 → setosa
1 → versicolor
2 → virginica
So the deep neural network learns to classify a flower into one of 3 species based on its measurements.

> code:
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.datasets import load_iris
from sklearn.preprocessing import OneHotEncoder, StandardScaler
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# Import additional libraries
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import seaborn as sns

# Load dataset
iris = load_iris()
X = iris.data
y = iris.target.reshape(-1, 1)

# One-hot encode target labels
encoder = OneHotEncoder(sparse_output=False)
y = encoder.fit_transform(y)

# Normalize features
scaler = StandardScaler()
X = scaler.fit_transform(X)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Build the model
model = Sequential([
    Dense(16, input_shape=(X.shape[1],), activation='relu'),
    Dense(12, activation='relu'),
    Dense(3, activation='softmax')  # 3 classes
])

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(X_train, y_train, validation_data=(X_test, y_test),
                    epochs=50, batch_size=8, verbose=1)

# Evaluate the model
loss, acc = model.evaluate(X_test, y_test, verbose=0)
print(f"Test Accuracy: {acc*100:.2f}%")

# Predictions
y_pred_probs = model.predict(X_test)
y_pred = np.argmax(y_pred_probs, axis=1)
y_true = np.argmax(y_test, axis=1)

# Confusion matrix
cm = confusion_matrix(y_true, y_pred)

# Plot using seaborn heatmap
plt.figure(figsize=(6,5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=iris.target_names,
            yticklabels=iris.target_names)
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

# Plot training history
plt.figure(figsize=(12,5))

# Loss plot
plt.subplot(1,2,1)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.title("Model Loss")
plt.legend()

# Accuracy plot
plt.subplot(1,2,2)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.title("Model Accuracy")
plt.legend()

plt.show()


--------------------------------------------------------


EXP 3: write a program for object detection using pre-trained model

The program performs object detection using a pre-trained Faster R-CNN model from torchvision. 
The model has been trained on the COCO dataset, so it can recognize 80 common object categories like people, cars, animals, and more.
Essentially, the code leverages a powerful deep learning detection pipeline without building any model from scratch.
The model automatically identifies objects, localizes them with boxes, and provides classification labels—all in a single step.

How it works:
- Image preparation: The input image is converted into a tensor format suitable for the model.
- Model inference: The pre-trained Faster R-CNN takes the image tensor and predicts bounding boxes, class labels, and confidence scores for objects it detects in the image.
- Filtering predictions: Only objects with confidence scores above a chosen threshold are considered, to avoid clutter from low-confidence predictions.
- Visualization: Bounding boxes and labels are drawn on the image to indicate what the model detected and how confident it is for each object.

> code:
import torch
import torchvision
from torchvision import transforms
from PIL import Image
import matplotlib.pyplot as plt
import matplotlib.patches as patches

# Load a pre-trained Faster R-CNN model
model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)
model.eval()

# COCO class labels
COCO_INSTANCE_CATEGORY_NAMES = [
    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',
    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign',
    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',
    'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag',
    'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite',
    'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',
    'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana',
    'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',
    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table',
    'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',
    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock',
    'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'
]

# Transform for input image
transform = transforms.Compose([
    transforms.ToTensor()
])

# Load your test image (replace with your path)
image_path = "image_path.jpg"   # put your image path here
img = Image.open(image_path).convert("RGB")
img_tensor = transform(img)
img_tensor = img_tensor.unsqueeze(0)  # add batch dimension

# Run object detection
with torch.no_grad():
    predictions = model(img_tensor)

# Get boxes, labels, scores
boxes = predictions[0]['boxes']
labels = predictions[0]['labels']
scores = predictions[0]['scores']

# Plot results
fig, ax = plt.subplots(1, figsize=(12,9))
ax.imshow(img)

# Draw only boxes above a threshold
threshold = 0.7
for i, box in enumerate(boxes):
    if scores[i] >= threshold:
        x1, y1, x2, y2 = box
        rect = patches.Rectangle((x1, y1), x2-x1, y2-y1,
                                 linewidth=2, edgecolor='r', facecolor='none')
        ax.add_patch(rect)
        # Check if the label index is within the valid range
        if labels[i] < len(COCO_INSTANCE_CATEGORY_NAMES):
            label = f"{COCO_INSTANCE_CATEGORY_NAMES[labels[i]]}: {scores[i]:.2f}"
            ax.text(x1, y1, label, fontsize=10, color='white',
                    bbox=dict(facecolor='red', alpha=0.5))
        else:
            # Handle cases where the label index is out of range (optional)
            print(f"Warning: Predicted label index {labels[i]} is out of range.")


plt.axis("off")
plt.show()


---------------------------------------------

EXP 4: write a program for image segmentation using pre-trained model.


Image segmentation is the process of partitioning an image into meaningful regions or segments, usually at the pixel level. Unlike classification, which assigns a single label to the whole image, segmentation assigns a label to each pixel, effectively identifying object boundaries and separating foreground from background.

Uses DeepLabV3 + ResNet50 backbone pre-trained on Pascal VOC dataset.
Each pixel is classified into one of the pre-defined object classes.
A color map is applied to visualize different object regions.
Works without training from scratch—just loads a pre-trained model and applies it to a new image.

> code:

import torch
import torchvision
from torchvision import transforms
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np

# Load pre-trained DeepLabV3 model
model = torchvision.models.segmentation.deeplabv3_resnet50(pretrained=True)
model.eval()

# Define transform to convert image to tensor
transform = transforms.Compose([
    transforms.ToTensor(),
])

# Load image
image_path = "img.jpg"  # Replace with your image path
img = Image.open(image_path).convert("RGB")
img_tensor = transform(img).unsqueeze(0)  # Add batch dimension

# Run segmentation
with torch.no_grad():
    output = model(img_tensor)['out'][0]  # output shape: [num_classes, H, W]

# Get predicted class per pixel
pred = torch.argmax(output, dim=0).byte().cpu().numpy()

# Create a color map for visualization
num_classes = 21  # DeepLabV3 trained on 21 classes (VOC)
colors = np.random.randint(0, 255, size=(num_classes, 3), dtype=np.uint8)
seg_image = colors[pred]

# Display original image and segmentation
fig, (ax1, ax2) = plt.subplots(1,2, figsize=(12,6))
ax1.imshow(img)
ax1.set_title("Original Image")
ax1.axis("off")

ax2.imshow(seg_image)
ax2.set_title("Segmented Image")
ax2.axis("off")

plt.show()



-----------------------


EXP 5: Write a program to implement the autoencoder model for image compression

An autoencoder is a type of neural network designed to learn efficient representations of data, often for the purpose of dimensionality reduction or compression.
It consists of two main parts:
1. Encoder: Compresses the input data into a smaller latent representation (also called the bottleneck).
2. Decoder: Reconstructs the original data from the compressed latent representation.
The network is trained to minimize the difference between the input and the reconstructed output, usually using losses like Mean Squared Error (MSE) or Binary Cross-Entropy.

Autoencoder Architecture:
Encoder: Compresses input (28×28 pixels → 64-dimensional latent vector).
Decoder: Reconstructs the image from the compressed latent vector.
Training: The model tries to reconstruct its input and minimizes reconstruction loss.
Compression: The encoding_dim=64 acts as the compressed representation—much smaller than the original 784 pixels.
Visualization: We can compare original vs. reconstructed images to see how much information is preserved.

> code:
# Import libraries
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.layers import Input, Dense, Flatten, Reshape
from tensorflow.keras.datasets import mnist

# Load MNIST dataset
(x_train, _), (x_test, _) = mnist.load_data()
x_train = x_train.astype('float32') / 255.
x_test  = x_test.astype('float32') / 255.

# Flatten images for fully connected autoencoder
x_train_flat = x_train.reshape((len(x_train), 28*28))
x_test_flat  = x_test.reshape((len(x_test), 28*28))

# Define Autoencoder
input_dim = 28*28
encoding_dim = 64  # Compressed representation size

# Encoder
input_img = Input(shape=(input_dim,))
encoded = Dense(128, activation='relu')(input_img)
encoded = Dense(encoding_dim, activation='relu')(encoded)

# Decoder
decoded = Dense(128, activation='relu')(encoded)
decoded = Dense(input_dim, activation='sigmoid')(decoded)

# Autoencoder Model
autoencoder = Model(input_img, decoded)

# Compile the model
autoencoder.compile(optimizer='adam', loss='binary_crossentropy')

# Train the model
history = autoencoder.fit(x_train_flat, x_train_flat,
                          epochs=50,
                          batch_size=256,
                          shuffle=True,
                          validation_data=(x_test_flat, x_test_flat))

# Evaluate reconstruction
decoded_imgs = autoencoder.predict(x_test_flat)

# Plot original and reconstructed images
n = 10  # number of images to display
plt.figure(figsize=(20,4))
for i in range(n):
    # Original
    ax = plt.subplot(2, n, i+1)
    plt.imshow(x_test_flat[i].reshape(28,28), cmap='gray')
    plt.axis('off')
    
    # Reconstructed
    ax = plt.subplot(2, n, i+n+1)
    plt.imshow(decoded_imgs[i].reshape(28,28), cmap='gray')
    plt.axis('off')
plt.show()

# Plot training loss
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.title("Autoencoder Training Loss")
plt.legend()
plt.show()


--------------------------

EXP 6: write a program to implement the autoencoder model for image denoising

An autoencoder is a type of neural network designed to learn efficient representations of data, often for the purpose of dimensionality reduction or compression.
It consists of two main parts:
1. Encoder: Compresses the input data into a smaller latent representation (also called the bottleneck).
2. Decoder: Reconstructs the original data from the compressed latent representation.
The network is trained to minimize the difference between the input and the reconstructed output, usually using losses like Mean Squared Error (MSE) or Binary Cross-Entropy.

Noise Injection: Random Gaussian noise is added to input images to create noisy versions.
Autoencoder Architecture:
- Encoder: Compresses noisy images into a smaller latent representation.
- Decoder: Reconstructs clean images from the latent vector.
Training Objective: Minimize the difference between the reconstructed images and the original clean images.
Result: After training, the autoencoder can remove noise from new images, effectively performing image denoising.

> code:
# Import libraries
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.layers import Input, Dense, Flatten, Reshape
from tensorflow.keras.datasets import mnist

# Load MNIST dataset
(x_train, _), (x_test, _) = mnist.load_data()
x_train = x_train.astype('float32') / 255.
x_test  = x_test.astype('float32') / 255.

# Flatten images for fully connected autoencoder
x_train_flat = x_train.reshape((len(x_train), 28*28))
x_test_flat  = x_test.reshape((len(x_test), 28*28))

# Define Autoencoder
input_dim = 28*28
encoding_dim = 64  # Compressed representation size

# Encoder
input_img = Input(shape=(input_dim,))
encoded = Dense(128, activation='relu')(input_img)
encoded = Dense(encoding_dim, activation='relu')(encoded)

# Decoder
decoded = Dense(128, activation='relu')(encoded)
decoded = Dense(input_dim, activation='sigmoid')(decoded)

# Autoencoder Model
autoencoder = Model(input_img, decoded)

# Compile the model
autoencoder.compile(optimizer='adam', loss='binary_crossentropy')

# Train the model
history = autoencoder.fit(x_train_flat, x_train_flat,
                          epochs=50,
                          batch_size=256,
                          shuffle=True,
                          validation_data=(x_test_flat, x_test_flat))

# Evaluate reconstruction
decoded_imgs = autoencoder.predict(x_test_flat)

# Plot original and reconstructed images
n = 10  # number of images to display
plt.figure(figsize=(20,4))
for i in range(n):
    # Original
    ax = plt.subplot(2, n, i+1)
    plt.imshow(x_test_flat[i].reshape(28,28), cmap='gray')
    plt.axis('off')
    
    # Reconstructed
    ax = plt.subplot(2, n, i+n+1)
    plt.imshow(decoded_imgs[i].reshape(28,28), cmap='gray')
    plt.axis('off')
plt.show()

# Plot training loss
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.title("Autoencoder Training Loss")
plt.legend()
plt.show()




------------------------


EXP 7: Develop a RNN based model for sentiment analysis and apply it to a test dataset

Sentiment in text depends on word order and context. Example: “not good” vs “good” → same words, opposite meaning.
Traditional models (like Bag-of-Words) ignore sequence information.
Recurrent Neural Networks (RNNs) are designed for sequential data, processing words one by one while maintaining a hidden state that captures past information.

Dataset:
IMDB dataset contains 25,000 movie reviews labeled positive/negative.
Reviews are sequences of word indices (words are mapped to integers).

Preprocessing:
Pad sequences so all reviews have the same length (max_len=200).

RNN Model:
Embedding layer: Converts word indices into dense vectors.
SimpleRNN layer: Processes sequential information in the review to capture context.
Dense output layer: Single neuron with sigmoid activation for binary classification.

Training:
Model learns to predict sentiment from sequences of words using binary cross-entropy loss.

Evaluation & Prediction:
Test set accuracy is computed.
Individual predictions can be made for new reviews.

> code:
# Import libraries
import tensorflow as tf
from tensorflow.keras.datasets import imdb
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, SimpleRNN, Dense
import matplotlib.pyplot as plt

# Parameters
vocab_size = 10000  # Top 10,000 words
max_len = 200       # Max sequence length
embedding_dim = 32

# Load dataset
(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)

# Pad sequences to ensure uniform length
x_train = pad_sequences(x_train, maxlen=max_len)
x_test  = pad_sequences(x_test,  maxlen=max_len)

# Build RNN model
model = Sequential([
    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len),
    SimpleRNN(64, activation='tanh'),
    Dense(1, activation='sigmoid')
])

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(x_train, y_train,
                    epochs=5,
                    batch_size=64,
                    validation_split=0.2)

# Evaluate on test dataset
loss, acc = model.evaluate(x_test, y_test)
print(f"Test Accuracy: {acc*100:.2f}%")

# Plot training history
plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.title("Loss History")
plt.legend()

plt.subplot(1,2,2)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.title("Accuracy History")
plt.legend()
plt.show()

# Get IMDB word index
word_index = imdb.get_word_index()
reverse_word_index = {value: key for key, value in word_index.items()}

def decode_review(encoded_review):
    # Map indices back to words (offset by 3 for special tokens in Keras IMDB)
    return ' '.join([reverse_word_index.get(i - 3, "?") for i in encoded_review if i >= 3])

# Example prediction
sample_review = x_test[0] 

# Example prediction
sample_text = x_test[0].reshape(1, -1)  # first test sample
pred = model.predict(sample_text)
print("Review text:\n", decode_review(x_test[0]))
print("Predicted Sentiment:", "Positive" if pred[0][0]>0.5 else "Negative")
print("Actual Sentiment:", "Positive" if y_test[0]==1 else "Negative")


----------------------------


EXP 8: design and implement a CNN model model for digit recognition application

CNNs are designed for image data. They capture local patterns (edges, corners, shapes) with convolutional filters.
Pooling layers reduce dimensionality, keeping important features.

Architecture Explained:
Conv2D layers: Learn features like strokes and curves of digits.
MaxPooling: Downsamples while keeping key information.
Dense layers: Perform classification based on extracted features.
Softmax output: Gives probability distribution across 10 digit classes.

How It Works:
Input Representation
The MNIST dataset provides 28×28 grayscale images of handwritten digits.
Each image is normalized (scaled between 0 and 1) and reshaped to fit CNN’s expected format (height, width, channels).

Feature Extraction (Convolution + Pooling)
Convolutional layers apply small filters (e.g., 3×3) across the image.
Early filters learn low-level features like edges, lines, and curves.
Deeper filters learn high-level patterns like loops or digit-specific shapes.

Pooling layers (max pooling) downsample the image representation.
This makes the model more efficient and less sensitive to small distortions (like a digit written slightly shifted).

Flattening & Fully Connected Layers
After feature extraction, the output feature maps are flattened into a 1D vector.
This vector is passed to dense layers, which combine the extracted features to make a decision.
A Dropout layer is used to prevent overfitting by randomly ignoring some neurons during training.

Classification Layer (Softmax)
The final layer has 10 output neurons (one for each digit 0–9).
The softmax function converts outputs into probabilities.
Example: Input image → output [0.01, 0.02, ..., 0.90, ...] → model predicts digit “7”.

Training Process
The model is trained using categorical cross-entropy loss.
The Adam optimizer adjusts the filter weights and neuron connections.
Training happens in epochs, gradually reducing loss and improving accuracy.

> code:
# Import libraries
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.datasets import mnist
from tensorflow.keras.utils import to_categorical
import matplotlib.pyplot as plt

# Load MNIST dataset
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# Normalize and reshape
x_train = x_train.astype('float32') / 255.0
x_test  = x_test.astype('float32') / 255.0
x_train = x_train.reshape(-1, 28, 28, 1)  # (samples, height, width, channels)
x_test  = x_test.reshape(-1, 28, 28, 1)

# One-hot encode labels
y_train = to_categorical(y_train, 10)
y_test  = to_categorical(y_test, 10)

# Build CNN model
model = Sequential([
    Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)),
    MaxPooling2D(pool_size=(2,2)),
    Conv2D(64, kernel_size=(3,3), activation='relu'),
    MaxPooling2D(pool_size=(2,2)),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(10, activation='softmax')   # 10 classes (digits 0–9)
])

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(x_train, y_train, epochs=5, batch_size=128,
                    validation_data=(x_test, y_test))

# Evaluate on test data
loss, acc = model.evaluate(x_test, y_test, verbose=0)
print(f"Test Accuracy: {acc*100:.2f}%")

# Plot accuracy and loss
plt.figure(figsize=(12,5))

plt.subplot(1,2,1)
plt.plot(history.history['accuracy'], label="Train Acc")
plt.plot(history.history['val_accuracy'], label="Val Acc")
plt.title("Model Accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()

plt.subplot(1,2,2)
plt.plot(history.history['loss'], label="Train Loss")
plt.plot(history.history['val_loss'], label="Val Loss")
plt.title("Model Loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()

plt.show()

# Test prediction on a sample
import numpy as np
sample = x_test[0].reshape(1,28,28,1)
pred = model.predict(sample)
print("Predicted Digit:", np.argmax(pred))

# Show the actual image
plt.imshow(x_test[0].reshape(28,28), cmap="gray")
plt.title(f"Actual Digit: {np.argmax(y_test[0])}")
plt.axis("off")
plt.show()

